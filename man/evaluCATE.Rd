% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/evaluCATE.R
\name{evaluCATE}
\alias{evaluCATE}
\title{CATEs Evaluation}
\usage{
evaluCATE(
  Y_tr,
  Y_val,
  D_tr,
  D_val,
  X_tr,
  X_val,
  cates_val,
  strategies = c("wr_none", "wr_cddf1", "wr_cddf2", "wr_mck1", "ht_none", "ht_cddf1",
    "ht_cddf2", "ht_mck1", "ht_mck2", "ht_mck3", "aipw"),
  pscore_val = NULL,
  mu_val = NULL,
  mu0_val = NULL,
  mu1_val = NULL,
  n_groups = 5,
  beneficial = TRUE,
  n_boot = 200,
  verbose = TRUE
)
}
\arguments{
\item{Y_tr}{Observed outcomes from the training sample.}

\item{Y_val}{Observed outcomes from the validation sample.}

\item{D_tr}{Treatment indicator for the training sample.}

\item{D_val}{Treatment indicator for the validation sample.}

\item{X_tr}{Covariate matrix for the training sample (no intercept).}

\item{X_val}{Covariate matrix for the validation sample (no intercept).}

\item{cates_val}{CATE predictions on the validation sample. Must be produced by a model estimated using only the training sample.}

\item{strategies}{Character vector with the names of the strategies to implement. Admitted values are \code{"wr_none"}, \code{"wr_cddf1"}, \code{"wr_cddf2"}, \code{"wr_mck1"}, \code{"ht_none"}, \code{"ht_cddf1"}, \code{"ht_cddf2"}, \code{"ht_mck1"}, \code{"ht_mck2"}, \code{"ht_mck3"}, \code{"aipw"}.}

\item{pscore_val}{Propensity scores predictions on the validation sample. Must be produced by a model estimated using only the training sample (unless the propensity score is known, in which case we provide the true values).}

\item{mu_val}{Conditional mean predictions on the validation sample. Must be produced by a model estimated using only the training sample.}

\item{mu0_val}{Control units' conditional mean predictions on the validation sample. Must be produced by a model estimated using only the training sample.}

\item{mu1_val}{Treated units' conditional mean predictions on the validation sample. Must be produced by a model estimated using only the training sample.}

\item{n_groups}{Number of groups to be formed for the GATES analysis.}

\item{beneficial}{Logical, whether the treatment is beneficial to units. If \code{TRUE}, units are ranked according to decreasing values of \code{cates} to estimate the RATEs, otherwise they are ranked according to increasing values of \code{cates}.}

\item{n_boot}{Number of bootstrap replications to estimate the standard error of the RATE estimates.}

\item{verbose}{Logical, set to FALSE to prevent the function from printing the progresses.}
}
\value{
An \code{evaluCATE} object.
}
\description{
Evaluates the quality of CATEs estimates by estimating the best linear predictor (BLP) of the actual CATEs using the estimated
CATEs, the sorted group average treatment effects (GATES), and the rank-weighted average treatment effect (RATE) induced by
the estimated CATEs.
}
\details{
To estimate BLP, GATES, and RATEs, the user must provide observations on the outcomes, the treatment status, and the covariates of units in the training and validation samples separately.
Additionally, the user must provide CATE predictions on the validation sample obtained from a model estimated using only the training sample.\cr

\code{\link{evaluCATE}} implements a number of strategies to estimate the BLP and the GATES. Most of them involve fitting a suitable linear model. The linear models differ according to the
different identification strategies. Furthermore, for each strategy, there exist various sets of constructed covariates that one can add to reduce the variance of the estimation. \code{\link{evaluCATE}}
fits and returns all these possible models. GATES are also estimated using a nonparametric approach. Check the online
\href{https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html}{short tutorial} for details.\cr

For the linear models, standard errors are estimated using the Eicker-Huber-White estimator. These standard errors are then used to test three distinct hypotheses of effect heterogeneity: whether
all GATES are equal to each other, whether the largest and the smallest GATES are different from each other, and whether the differences in the GATES across all pairs of groups are zero.
For the last test, we adjust p-values to account for multiple hypotheses testing using Holm's procedure and report the median of the adjusted p-values. The nonparametric approach tests only the first
of these hypotheses. Check the \href{https://riccardo-df.github.io/evaluCATE/articles/hypotheses-testing.html}{hypotheses testing vignette} for details.\cr

Some of the linear models involve covariates that depend on particular nuisance functions, e.g., propensity score and conditional mean of the outcome
(check the online \href{https://riccardo-df.github.io/evaluCATE/articles/denoising.html}{denoising vignette} for details about these covariates). The user can supply estimates of these functions by using the
optional arguments \code{pscore}, \code{mu}, \code{mu0}, and \code{mu1}. Be careful, as these must be obtained using only the training sample. If not provided by the user, these functions are estimated internally
via honest \code{\link[grf]{regression_forest}}s using only the training sample. \cr

To estimate the BLP and GATES using the AIPW strategy, doubly-robust scores are estimated internally using the validation sample via 5-fold cross fitting and honest regression forests (see the
\code{\link[aggTrees]{dr_scores}} function for details). The same doubly-robust scores are also used to estimate the RATEs.\cr

Groups are constructed by cutting the distribution of \code{cates} into \code{n_groups} quantiles. If this leads to one or more groups composed of only treated or only control units, the function raises an error.\cr

Two different RATEs are estimated: AUTOC and QINI coefficient. Sample-averaging estimators are employed. Standard errors are estimated by the standard deviation of the bootstrap estimates obtained using the half-sample bootstrap.
}
\examples{
\donttest{## Generate data.
set.seed(1986)

n <- 1000
k <- 2

X <- matrix(rnorm(n * k), ncol = k)
colnames(X) <- paste0("x", seq_len(k))
D <- rbinom(n, size = 1, prob = 0.5)
mu0 <- 0.5 * X[, 1]
mu1 <- 0.5 * X[, 1] + X[, 2]
Y <- mu0 + D * (mu1 - mu0) + rnorm(n)

## Sample split.
train_idx <- sample(c(TRUE, FALSE), length(Y), replace = TRUE)

X_tr <- X[train_idx, ]
X_val <- X[!train_idx, ]

D_tr <- D[train_idx]
D_val <- D[!train_idx]

Y_tr <- Y[train_idx]
Y_val <- Y[!train_idx]

## CATEs estimation.
library(grf)

forest <- causal_forest(X_tr, Y_tr, D_tr) # We use only the training sample.
cates_val <- predict(forest, X_val)$predictions # We predict on the validation sample.

## CATEs evaluation. Estimate all nuisances internally. 
pscore_val <- rep(0.5, length(Y_val))
evaluation <- evaluCATE(Y_tr, Y_val, D_tr, D_val, X_tr, X_val, cates_val, pscore_val = pscore_val)

## Generic S3 methods.
summary(evaluation, target = "BLP")
summary(evaluation, target = "BLP", latex = TRUE)

summary(evaluation, target = "GATES")
summary(evaluation, target = "GATES", latex = TRUE)

plot(evaluation, target = "GATES")
plot(evaluation, target = "TOC")}

}
\seealso{
Other functions
}
\author{
Riccardo Di Francesco
}
