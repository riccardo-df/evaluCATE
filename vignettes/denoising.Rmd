---
title: "Denoise Terms"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Denoise Terms}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

As described in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html), some estimation strategies for the BLP and the GATES involve fitting suitable linear models. These regressions allow the inclusion of optional constructed covariates which are not necessary for identifying the targets but can significantly reduce the variance of the estimation. On this page, we discuss which covariates can be incorporated in the regressions.

The notation is the same as in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html).

There are several possible sets of constructed covariates that one can include in the regressions to reduce the variance of the estimation. Some of these sets have been proposed by Chernozukov et al. (2017), while others are new. For both the BLP and the GATES results, the `evaluCATE` function returns a bunch of fitted models, one for each of these sets. Thus, the user can compare the results across the different models.

The optional constructed covariates depend on the nuisance functions $p ( \cdot )$, $\mu ( \cdot )$, $\mu_0 ( \cdot )$, and $\mu_1 ( \cdot )$. The `evaluCATE` function has four optional arguments that we can use to supply estimates of these nuisance parameter. Be careful, as these estimates must be obtained using only the training sample. If not provided by the user, these functions are estimated internally via honest regression forests using only the training sample.

Suppose that we assign the results of the `evaluCATE` function call to a variable called `evaluation`.

```{r call-main, eval = FALSE}
evaluation <- evaluCATE(Y, D, X, cates, is_train = train_idx)
```

In the following, we list the covariates that are included in the fitted models returned by the `evaluCATE` function. 

### Weighted Residual
The `evaluCATE` function returns four different BLP and GATES models fitted using the weighted residual strategy.

- BLP:

  * `evaluation$BLP$wr_none` &rarr; The model discussed in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html);
  * `evaluation$BLP$wr_cddf1` &rarr; The model discussed in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html) plus $\hat{\mu}_0 ( X_i )$;
  * `evaluation$BLP$wr_cddf2` &rarr; The model discussed in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html) plus $1, \hat{\mu}_0 ( X_i ), p ( X_i ), p ( X_i ) \cdot \hat{\tau} ( X_i )$;
  * `evaluation$BLP$wr_mck1` &rarr; The model discussed in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html) plus $\hat{\mu} ( X_i )$.

- GATES:
  * `evaluation$GATES$wr_none` &rarr; The model discussed in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html);
  * `evaluation$GATES$wr_cddf1` &rarr; The model discussed in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html) plus $\hat{\mu}_0 ( X_i )$; 
  * `evaluation$GATES$wr_cddf2` &rarr; The model discussed in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html) plus $\hat{\mu}_0 ( X_i ), p ( X_i ) \cdot \mathbb{1} (G_1), \dots, p ( X_i ) \cdot \mathbb{1} (G_K)$; 
  * `evaluation$GATES$wr_mck1` &rarr; The model discussed in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html) plus $\hat{\mu} ( X_i )$.
  
### Horvitz-Thompson 
The `evaluCATE` function returns six different BLP and GATES models fitted using the Horvitz-Thompson transformation strategy.

- BLP:
  * `evaluation$BLP$ht_none` &rarr; The model discussed in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html);
  * `evaluation$BLP$ht_cddf1` &rarr; The model discussed in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html) plus $H_i \cdot \hat{\mu}_0 ( X_i )$;
  * `evaluation$BLP$ht_cddf2` &rarr; The model discussed in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html) plus $H_i \cdot \hat{\mu}_0 ( X_i ), H_i \cdot p ( X_i ), H_i \cdot p ( X_i ) \cdot \hat{\tau} ( X_i )$;
  * `evaluation$BLP$ht_mck1` &rarr; The model discussed in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html) plus $H_i \cdot \hat{\mu}_0 ( X_i ), H_i \cdot [ 1 - p ( X_i ) ] \cdot \hat{\tau} ( X_i )$;
  * `evaluation$BLP$ht_mck2` &rarr; The model discussed in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html) plus $H_i \cdot p ( X_i ), H_i \cdot p ( X_i ) \cdot \hat{\mu}_0 ( X_i ), H_i \cdot [ 1 - p ( X_i ) ] \cdot \hat{\mu}_1 ( X_i )$;
  * `evaluation$BLP$ht_mck3` &rarr; The model discussed in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html) plus $H_i \cdot p ( X_i ), \{ H_i \cdot p ( X_i ) \cdot \hat{\mu}_0 ( X_i ) + H_i \cdot [ 1 - p ( X_i ) ] \cdot \hat{\mu}_1 ( X_i ) \}$.

- GATES:
  * `evaluation$GATES$ht_none` &rarr; The model discussed in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html);
  * `evaluation$GATES$ht_cddf1` &rarr; The model discussed in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html) plus  $H_i \cdot \hat{\mu}_0 ( X_i )$; 
  * `evaluation$GATES$ht_cddf2` &rarr; The model discussed in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html) plus $H_i \cdot \hat{\mu}_0 ( X_i ), H_i \cdot p ( X_i ) \cdot \mathbb{1} (G_1), \dots, H_i \cdot p ( X_i ) \cdot \mathbb{1} (G_K)$; 
  * `evaluation$GATES$ht_mck1` &rarr; The model discussed in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html) plus $H_i \cdot \hat{\mu}_0 ( X_i ), H_i \cdot [ 1 - p ( X_i ) ] \cdot \hat{\tau} ( X_i )$; 
  * `evaluation$GATES$ht_mck2` &rarr; The model discussed in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html) plus $H_i \cdot p ( X_i ), H_i \cdot p ( X_i ) \cdot \hat{\mu}_0 ( X_i ), H_i \cdot [ 1 - p ( X_i ) ] \cdot \hat{\mu}_1 ( X_i )$; 
  * `evaluation$GATES$ht_mck3` &rarr; The model discussed in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html) plus $H_i \cdot p ( X_i ), \{ H_i \cdot p ( X_i ) \cdot \hat{\mu}_0 ( X_i ) + H_i \cdot [ 1 - p ( X_i ) ] \cdot \hat{\mu}_1 ( X_i ) \}$. 
  
### AIPW
The `evaluCATE` function returns only one BLP and GATES model fitted using the AIPW strategy.  

- BLP:
  * `evaluation$BLP$aipw` &rarr; The model discussed in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html).
  
- GATES:
  * `evaluation$GATES$aipw` &rarr; The model discussed in the [short tutorial](https://riccardo-df.github.io/evaluCATE/articles/evaluCATE-short-tutorial.html).
